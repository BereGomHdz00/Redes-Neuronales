{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TSAP3_Practica-CNN_BDGL\n",
        "\n",
        "* Ballesteros Rios Erick David\n",
        "* Diaz Lopez Edgar Gustavo\n",
        "* Gómez Hernandez Berenice\n",
        "* López Miguel Hugo\n"
      ],
      "metadata": {
        "id": "kTO3J9szv1LV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX5RRSKDL42N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.src.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import keras.utils as image\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.src.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ],
      "metadata": {
        "id": "q4EXRr5RmSO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/dataset_imgs/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkQX5r6DMhWJ",
        "outputId": "628cd551-b210-4a14-c91c-a114dc152f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dogs and cats"
      ],
      "metadata": {
        "id": "NROC1uyPiUpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"dog-and-cat/\"\n",
        "\n",
        "# Obtener la lista de clases (nombre de las carpetas)\n",
        "classes = os.listdir(data_dir)"
      ],
      "metadata": {
        "id": "UjoqDAOnNd5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 64\n",
        "img_width = 64\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "training_set = train_datagen.flow_from_directory('dog-and-cat/training_set',\n",
        "                                                 target_size=(64,64),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale= 1./255)\n",
        "test_set = test_datagen.flow_from_directory('dog-and-cat/test_set',\n",
        "                                            target_size = (64,64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JujeImPWNkhk",
        "outputId": "f354862a-1cf7-4efe-98e7-02be601ab343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8001 images belonging to 2 classes.\n",
            "Found 2001 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "ThGqOsuOOECD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(training_set, epochs=25, steps_per_epoch=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYxw4NnvOLhK",
        "outputId": "d9079cfe-e612-4cdd-ba3a-afeab62c1f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "10/10 [==============================] - 37s 3s/step - loss: 0.7042 - accuracy: 0.4781\n",
            "Epoch 2/25\n",
            "10/10 [==============================] - 32s 3s/step - loss: 0.6953 - accuracy: 0.4906\n",
            "Epoch 3/25\n",
            "10/10 [==============================] - 34s 3s/step - loss: 0.6937 - accuracy: 0.5094\n",
            "Epoch 4/25\n",
            "10/10 [==============================] - 33s 3s/step - loss: 0.6928 - accuracy: 0.5188\n",
            "Epoch 5/25\n",
            "10/10 [==============================] - 29s 3s/step - loss: 0.6912 - accuracy: 0.5500\n",
            "Epoch 6/25\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.6942 - accuracy: 0.4812\n",
            "Epoch 7/25\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.6877 - accuracy: 0.5250\n",
            "Epoch 8/25\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.6868 - accuracy: 0.5625\n",
            "Epoch 9/25\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.6733 - accuracy: 0.5969\n",
            "Epoch 10/25\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.6708 - accuracy: 0.5625\n",
            "Epoch 11/25\n",
            "10/10 [==============================] - 24s 2s/step - loss: 0.6737 - accuracy: 0.5594\n",
            "Epoch 12/25\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6345 - accuracy: 0.6187\n",
            "Epoch 13/25\n",
            "10/10 [==============================] - 24s 2s/step - loss: 0.6635 - accuracy: 0.6000\n",
            "Epoch 14/25\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.6558 - accuracy: 0.5779\n",
            "Epoch 15/25\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.6611 - accuracy: 0.6031\n",
            "Epoch 16/25\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.6759 - accuracy: 0.5750\n",
            "Epoch 17/25\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.6558 - accuracy: 0.6187\n",
            "Epoch 18/25\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.6512 - accuracy: 0.6375\n",
            "Epoch 19/25\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.6272 - accuracy: 0.6375\n",
            "Epoch 20/25\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.6294 - accuracy: 0.6625\n",
            "Epoch 21/25\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6125 - accuracy: 0.6594\n",
            "Epoch 22/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6238 - accuracy: 0.6313\n",
            "Epoch 23/25\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6204 - accuracy: 0.6625\n",
            "Epoch 24/25\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.6394 - accuracy: 0.6367\n",
            "Epoch 25/25\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.6679 - accuracy: 0.6125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x798ad23b8040>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_loss, test_accuracy = model.evaluate(test_set)\n",
        "print('Precisión en el conjunto de prueba:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qxJdJNpkEM6",
        "outputId": "6ab2eb24-a246-4922-84ee-a32a3861f720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 463s 7s/step - loss: 0.6282 - accuracy: 0.6412\n",
            "Precisión en el conjunto de prueba: 0.6411793828010559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10 animales"
      ],
      "metadata": {
        "id": "30sCKCdjkQ8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir2 = \"10-image-class-animals/\"\n",
        "\n",
        "# Obtener la lista de clases (nombre de las carpetas)\n",
        "classes = os.listdir(data_dir2)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2)  # Porcentaje de datos para validación\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    data_dir2,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # Utiliza class_mode='categorical' para múltiples clases\n",
        "    subset='training')  # Indica que se usarán datos de entrenamiento\n",
        "\n",
        "# Configurar otro generador para cargar las imágenes de validación\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir2,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # Utiliza class_mode='categorical' para múltiples clases\n",
        "    subset='validation')  # Indica que se usarán datos de validación"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQq4VYXKkSp0",
        "outputId": "0a79f906-09f6-4b26-8e46-308c100a6ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20900 images belonging to 10 classes.\n",
            "Found 5221 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    # Capa convolucional 1\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Capa convolucional 2\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Capa convolucional 3\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Capa de agrupación plana\n",
        "    Flatten(),\n",
        "    # Capa completamente conectada 1 con Dropout\n",
        "    Dense(128, activation='relu'),\n",
        "    # Capa de salida\n",
        "    Dense(len(classes), activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Cambiado a categorical_crossentropy para usar class_mode 'categorical'\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tIliOkUFmGN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(generator,\n",
        "                    steps_per_epoch=4,\n",
        "                    epochs=15,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnZ8awcQmbkp",
        "outputId": "349817ef-4ec3-4cc6-9030-7ea7b6522962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "4/4 [==============================] - 97s 29s/step - loss: 2.2823 - accuracy: 0.1172 - val_loss: 2.2158 - val_accuracy: 0.1406\n",
            "Epoch 2/15\n",
            "4/4 [==============================] - 51s 15s/step - loss: 2.2193 - accuracy: 0.2422 - val_loss: 2.2221 - val_accuracy: 0.1797\n",
            "Epoch 3/15\n",
            "4/4 [==============================] - 64s 20s/step - loss: 2.2559 - accuracy: 0.1719 - val_loss: 2.2334 - val_accuracy: 0.1641\n",
            "Epoch 4/15\n",
            "4/4 [==============================] - 65s 20s/step - loss: 2.2482 - accuracy: 0.1328 - val_loss: 2.2214 - val_accuracy: 0.1719\n",
            "Epoch 5/15\n",
            "4/4 [==============================] - 49s 14s/step - loss: 2.1812 - accuracy: 0.1875 - val_loss: 2.2559 - val_accuracy: 0.1641\n",
            "Epoch 6/15\n",
            "4/4 [==============================] - 43s 12s/step - loss: 2.2010 - accuracy: 0.2109 - val_loss: 2.3019 - val_accuracy: 0.1406\n",
            "Epoch 7/15\n",
            "4/4 [==============================] - 64s 20s/step - loss: 2.1886 - accuracy: 0.2031 - val_loss: 2.2698 - val_accuracy: 0.1875\n",
            "Epoch 8/15\n",
            "4/4 [==============================] - 46s 13s/step - loss: 2.2306 - accuracy: 0.1719 - val_loss: 2.2245 - val_accuracy: 0.2109\n",
            "Epoch 9/15\n",
            "4/4 [==============================] - 43s 12s/step - loss: 2.2095 - accuracy: 0.2266 - val_loss: 2.2182 - val_accuracy: 0.2031\n",
            "Epoch 10/15\n",
            "4/4 [==============================] - 45s 14s/step - loss: 2.2472 - accuracy: 0.1719 - val_loss: 2.2359 - val_accuracy: 0.2344\n",
            "Epoch 11/15\n",
            "4/4 [==============================] - 43s 13s/step - loss: 2.1462 - accuracy: 0.1875 - val_loss: 2.1923 - val_accuracy: 0.1797\n",
            "Epoch 12/15\n",
            "4/4 [==============================] - 42s 12s/step - loss: 2.2204 - accuracy: 0.1875 - val_loss: 2.1818 - val_accuracy: 0.1797\n",
            "Epoch 13/15\n",
            "4/4 [==============================] - 41s 12s/step - loss: 2.2322 - accuracy: 0.1797 - val_loss: 2.1957 - val_accuracy: 0.2188\n",
            "Epoch 14/15\n",
            "4/4 [==============================] - 40s 12s/step - loss: 2.2126 - accuracy: 0.2031 - val_loss: 2.2158 - val_accuracy: 0.1484\n",
            "Epoch 15/15\n",
            "4/4 [==============================] - 39s 12s/step - loss: 2.1134 - accuracy: 0.2500 - val_loss: 2.2554 - val_accuracy: 0.2031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "test_loss, test_acc = model2.evaluate(validation_generator)\n",
        "print(f'Accuracy del modelo: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD7Jc-52r8g5",
        "outputId": "785634a7-0bf2-4ae5-de28-166c562e1966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164/164 [==============================] - 553s 3s/step - loss: 2.2626 - accuracy: 0.1846\n",
            "Accuracy del modelo: 0.18463896214962006\n"
          ]
        }
      ]
    }
  ]
}